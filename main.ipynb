{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import nltk\n",
    "import re\n",
    "import swifter\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_json(\"data/Electronics_5.json\", lines=True)\n",
    "\n",
    "# Filter & map ratings to sentiment\n",
    "def map_sentiment(rating):\n",
    "    if rating <= 2:\n",
    "        return \"negative\"\n",
    "    elif rating == 3:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "df['sentiment'] = df['overall'].apply(map_sentiment)\n",
    "df['reviewText'] = df['reviewText'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text) # rimozione punteggiatura\n",
    "    text = re.sub(r\"\\d+\", \"\", text) # rimozione numeri\n",
    "    text = \" \".join([word for word in text.split() if word not in stopwords.words(\"english\")])\n",
    "    return text\n",
    "\n",
    "df['cleaned'] = df['reviewText'].swifter.apply(clean_text)\n",
    "\n",
    "# Train-test split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['cleaned'], df['sentiment'], test_size=0.2, stratify=df['sentiment'], random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show comparison of original and cleaned reviews\n",
    "comparison_df = df[['reviewText', 'cleaned', 'sentiment']]\n",
    "print(comparison_df.head(10))  \n",
    "comparison_df.head(10)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Traditional Models ===\n",
    "\n",
    "# TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train = tfidf.fit_transform(train_texts)\n",
    "X_test = tfidf.transform(test_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, train_labels)\n",
    "lr_preds = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, train_labels)\n",
    "nb_preds = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, preds):\n",
    "    print(f\"\\n{name} Classification Report:\")\n",
    "    print(classification_report(test_labels, preds))\n",
    "    cm = confusion_matrix(test_labels, preds, labels=[\"negative\", \"neutral\", \"positive\"])\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=[\"Neg\", \"Neu\", \"Pos\"], yticklabels=[\"Neg\", \"Neu\", \"Pos\"])\n",
    "    plt.title(f\"{name} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(\"Logistic Regression\", lr_preds)\n",
    "evaluate_model(\"Naive Bayes\", nb_preds)\n",
    "\n",
    "# === Transformer-based Model ===\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "df['label'] = df['sentiment'].map(label_map)\n",
    "\n",
    "# Prepare dataset\n",
    "tokenized_data = tokenizer(list(df['reviewText']), padding=True, truncation=True, return_tensors='pt')\n",
    "dataset = Dataset.from_dict({\n",
    "    'input_ids': tokenized_data['input_ids'],\n",
    "    'attention_mask': tokenized_data['attention_mask'],\n",
    "    'label': df['label']\n",
    "})\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate BERT model\n",
    "bert_preds = trainer.predict(dataset['test']).predictions.argmax(-1)\n",
    "bert_labels = dataset['test']['label']\n",
    "print(\"\\nDistilBERT Classification Report:\")\n",
    "print(classification_report(bert_labels, bert_preds, target_names=[\"negative\", \"neutral\", \"positive\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
