{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/carminefa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import swifter\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_json(\"data/Electronics_5.json\", lines=True)\n",
    "\n",
    "# Filter & map ratings to sentiment\n",
    "def map_sentiment(rating):\n",
    "    if rating <= 2:\n",
    "        return \"negative\"\n",
    "    elif rating == 3:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "df['sentiment'] = df['overall'].apply(map_sentiment)\n",
    "df['reviewText'] = df['reviewText'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 19) (2239326290.py, line 19)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdf['cleaned\u001b[39m\n       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 19)\n"
     ]
    }
   ],
   "source": [
    "# Utilizzo modello ottimizzato spaCy (solo tagger/tokenizer/lemmatizer)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "\n",
    "# Funzione di pulizia batch\n",
    "def batch_clean(text_series):\n",
    "    docs = nlp.pipe(text_series, batch_size=1000, n_process=2)\n",
    "    return [\n",
    "        \" \".join(\n",
    "            [t.lemma_ for t in doc if not t.is_stop and not t.is_punct and not t.like_num]\n",
    "        )\n",
    "        for doc in docs\n",
    "    ]\n",
    "\n",
    "# 4. Pulizia del testo\n",
    "df['cleaned'] = batch_clean(df['reviewText'])\n",
    "\n",
    "# 5. Split del dataset\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['cleaned'], df['sentiment'], test_size=0.2, stratify=df['sentiment'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show comparison of original and cleaned reviews\n",
    "comparison_df = df[['reviewText', 'cleaned', 'sentiment']]\n",
    "print(comparison_df.head(10))  \n",
    "comparison_df.head(10)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Traditional Models ===\n",
    "\n",
    "# TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train = tfidf.fit_transform(train_texts)\n",
    "X_test = tfidf.transform(test_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, train_labels)\n",
    "lr_preds = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, train_labels)\n",
    "nb_preds = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, preds):\n",
    "    print(f\"\\n{name} Classification Report:\")\n",
    "    print(classification_report(test_labels, preds))\n",
    "    cm = confusion_matrix(test_labels, preds, labels=[\"negative\", \"neutral\", \"positive\"])\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=[\"Neg\", \"Neu\", \"Pos\"], yticklabels=[\"Neg\", \"Neu\", \"Pos\"])\n",
    "    plt.title(f\"{name} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(\"Logistic Regression\", lr_preds)\n",
    "evaluate_model(\"Naive Bayes\", nb_preds)\n",
    "\n",
    "# === Transformer-based Model ===\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "df['label'] = df['sentiment'].map(label_map)\n",
    "\n",
    "# Prepare dataset\n",
    "tokenized_data = tokenizer(list(df['reviewText']), padding=True, truncation=True, return_tensors='pt')\n",
    "dataset = Dataset.from_dict({\n",
    "    'input_ids': tokenized_data['input_ids'],\n",
    "    'attention_mask': tokenized_data['attention_mask'],\n",
    "    'label': df['label']\n",
    "})\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate BERT model\n",
    "bert_preds = trainer.predict(dataset['test']).predictions.argmax(-1)\n",
    "bert_labels = dataset['test']['label']\n",
    "print(\"\\nDistilBERT Classification Report:\")\n",
    "print(classification_report(bert_labels, bert_preds, target_names=[\"negative\", \"neutral\", \"positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒ Word2Vec Embedding e Confronto\n",
    "\n",
    "In questa sezione, rappresentiamo ogni review come un vettore denso (dense embedding vector) generato da Word2Vec. \n",
    "Questo consente di catturare significati semantici e relazioni tra le parole, migliorando potenzialmente la capacitÃ  del classificatore.\n",
    "\n",
    "**Passaggi principali:**\n",
    "1. Preprocessing delle recensioni (tokenizzazione).\n",
    "2. Addestramento modello Word2Vec sul dataset.\n",
    "3. Conversione di ogni review in un vettore denso (media degli embedding delle parole).\n",
    "4. Addestramento e valutazione di un classificatore (es. Logistic Regression) usando questi vettori.\n",
    "5. Confronto delle metriche con il modello precedente (TF-IDF).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Tokenizzazione\n",
    "tokenized_reviews = [word_tokenize(review.lower()) for review in df['text']]\n",
    "\n",
    "# Addestramento modello Word2Vec\n",
    "w2v_model = Word2Vec(sentences=tokenized_reviews, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# Media degli embedding per ogni documento\n",
    "def document_vector(doc):\n",
    "    words = [word for word in word_tokenize(doc.lower()) if word in w2v_model.wv]\n",
    "    return np.mean(w2v_model.wv[words], axis=0) if words else np.zeros(100)\n",
    "\n",
    "X_w2v = np.array([document_vector(doc) for doc in df['text']])\n",
    "y = df['label']\n",
    "\n",
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_w2v, X_test_w2v, y_train, y_test = train_test_split(X_w2v, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Classificatore\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_w2v, y_train)\n",
    "y_pred = clf.predict(X_test_w2v)\n",
    "\n",
    "# Valutazione\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv-nlp-Feel-the-review",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
